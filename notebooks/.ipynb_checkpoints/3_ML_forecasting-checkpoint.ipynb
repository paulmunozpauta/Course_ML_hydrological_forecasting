{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcdb5c0d",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\"><img style=\"width: 30%;\" src=\"static/Logo_course.png\"></div>\n",
    "\n",
    "    \n",
    "\n",
    "Ing. Paul Muñoz, PhD.\n",
    "\n",
    "paul.andres.munoz@gmail.com  ;  paul.munozp@ucuenca.edu.ec\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ce37e",
   "metadata": {},
   "source": [
    "# Taller 4: Desarrollo de modelos de pronóstico hidrológico.\n",
    "\n",
    "En esta sesión vamos a:\n",
    "    - Desarrollar modelos de pronóstico para la cuenca del río Tomebamba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce59d2de",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.dates as dates\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import itertools\n",
    "\n",
    "def lagged_dataset(arr, num_steps, additional_arr, new_num_steps):\n",
    "    num_columns = arr.shape[1]\n",
    "    modified_rows = []\n",
    "    excluded_data = []\n",
    "    for i in range(num_steps, arr.shape[0]):\n",
    "        prev_rows = arr[i - num_steps:i]\n",
    "        current_row = arr[i]\n",
    "        new_row = np.concatenate((prev_rows.flatten(), current_row))\n",
    "        modified_rows.append(new_row)\n",
    "    result_array = np.array(modified_rows)\n",
    "    # Slicing the result_array to match the number of rows in modified_additional_arr\n",
    "    if result_array.shape[0] > additional_arr.shape[0]:\n",
    "        result_array = result_array[result_array.shape[0] - additional_arr.shape[0]:]\n",
    "\n",
    "    modified_rows = []\n",
    "    for i in range(new_num_steps, additional_arr.shape[0]):\n",
    "        prev_rows = additional_arr[i - new_num_steps:i]\n",
    "        current_row = additional_arr[i]\n",
    "        excluded_data.append(current_row[-1])  # Store excluded data\n",
    "        new_row = np.concatenate((prev_rows.flatten(), current_row[:-1]))  # Exclude last column\n",
    "        modified_rows.append(new_row)\n",
    "\n",
    "    modified_additional_arr = np.array(modified_rows)\n",
    "\n",
    "    # Adjust dimensions by removing rows from result_array or modified_additional_arr\n",
    "    min_rows = min(result_array.shape[0], modified_additional_arr.shape[0])\n",
    "    result_array = result_array[-min_rows:]\n",
    "    modified_additional_arr = modified_additional_arr[-min_rows:]\n",
    "    excluded_data = np.array(excluded_data)[-min_rows:]\n",
    "\n",
    "    # Concatenate result_array and modified_additional_arr\n",
    "    final_result = np.concatenate((result_array, modified_additional_arr), axis=1)\n",
    "\n",
    "    return final_result, np.array(excluded_data)[:, None]\n",
    "\n",
    "def lagged_dataset_pron(arr, num_steps, additional_arr, new_num_steps, lead_time):\n",
    "    num_columns = arr.shape[1]\n",
    "    modified_rows = []\n",
    "    excluded_data = []\n",
    "\n",
    "    for i in range(num_steps, arr.shape[0]):\n",
    "        prev_rows = arr[i - num_steps:i]\n",
    "        current_row = arr[i]\n",
    "        new_row = np.concatenate((prev_rows.flatten(), current_row))\n",
    "        modified_rows.append(new_row)\n",
    "\n",
    "    result_array = np.array(modified_rows)\n",
    "\n",
    "    # Slicing the result_array to match the number of rows in modified_additional_arr\n",
    "    if result_array.shape[0] > additional_arr.shape[0]:\n",
    "        result_array = result_array[result_array.shape[0] - additional_arr.shape[0]:]\n",
    "\n",
    "    modified_rows = []\n",
    "    for i in range(new_num_steps, additional_arr.shape[0]):\n",
    "        prev_rows = additional_arr[i - new_num_steps:i]\n",
    "        current_row = additional_arr[i]\n",
    "        excluded_data.append(current_row[-1])  # Store excluded data\n",
    "        new_row = np.concatenate((prev_rows.flatten(), current_row))  # Include last column\n",
    "        modified_rows.append(new_row)\n",
    "\n",
    "    modified_additional_arr = np.array(modified_rows)\n",
    "\n",
    "    # Adjust dimensions by removing rows from result_array or modified_additional_arr\n",
    "    min_rows = min(result_array.shape[0], modified_additional_arr.shape[0])\n",
    "    result_array = result_array[-min_rows:]\n",
    "    modified_additional_arr = modified_additional_arr[-min_rows:]\n",
    "    excluded_data = np.array(excluded_data)[-min_rows:]\n",
    "\n",
    "    # Shift excluded_data by lead_time\n",
    "    excluded_data = excluded_data[lead_time:]\n",
    "\n",
    "    # Concatenate result_array and modified_additional_arr\n",
    "    final_result = np.concatenate((result_array, modified_additional_arr), axis=1)\n",
    "\n",
    "    # Resize final_result and excluded_data to have the same number of rows\n",
    "    min_rows = min(final_result.shape[0], excluded_data.shape[0])\n",
    "    final_result = final_result[:min_rows]\n",
    "    excluded_data = excluded_data[:min_rows]\n",
    "\n",
    "    return final_result, np.array(excluded_data)[:, None]\n",
    "\n",
    "\n",
    "def calculate_hydro_metrics(simulations, evaluation):\n",
    "    sim_mean = np.mean(simulations, axis=0, dtype=np.float64)\n",
    "    obs_mean = np.mean(evaluation, dtype=np.float64)\n",
    "\n",
    "    r_num = np.sum((simulations - sim_mean) * (evaluation - obs_mean),\n",
    "                   axis=0, dtype=np.float64)\n",
    "    r_den = np.sqrt(np.sum((simulations - sim_mean) ** 2,\n",
    "                           axis=0, dtype=np.float64)\n",
    "                    * np.sum((evaluation - obs_mean) ** 2,\n",
    "                             dtype=np.float64))\n",
    "    r = r_num / r_den\n",
    "    # calculate error in spread of flow alpha\n",
    "    alpha = np.std(simulations, axis=0) / np.std(evaluation, dtype=np.float64)\n",
    "    # calculate error in volume beta (bias of mean discharge)\n",
    "    beta = (np.sum(simulations, axis=0, dtype=np.float64)\n",
    "            / np.sum(evaluation, dtype=np.float64))\n",
    "    # calculate the Kling-Gupta Efficiency KGE\n",
    "    kge = 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n",
    "    rmse = np.sqrt(np.mean((evaluation - simulations) ** 2,\n",
    "                            axis=0, dtype=np.float64))\n",
    "    pbias = (100 * np.sum(evaluation - simulations, axis=0, dtype=np.float64)\n",
    "              / np.sum(evaluation))\n",
    "    r2 = 1 - (np.sum((evaluation - simulations)**2) / np.sum((evaluation - np.mean(evaluation))**2))\n",
    "    return kge, rmse, pbias, r2\n",
    "np.random.seed(22)\n",
    "import random\n",
    "random.seed(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a3064",
   "metadata": {},
   "source": [
    "## Seleccionar carpeta del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85381a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.getcwd()+'/data/'\n",
    "folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745e22b",
   "metadata": {},
   "source": [
    "## Importar datos de precipitación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f65ceb",
   "metadata": {},
   "source": [
    "### Precipitación satelital"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e409de",
   "metadata": {},
   "source": [
    "Leer datos de la cuenca del río Tomebamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a895238",
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_satellite= pd.read_table(folder+'PERSIANN-CCS_UTC_daily_tomebamba_full.csv', sep=',')\n",
    "precipitation_satellite.rename(columns={'Unnamed: 0':'Date'},inplace=True)\n",
    "precipitation_satellite['Date'] = precipitation_satellite.Date.apply(lambda x: pd.to_datetime(x,dayfirst=True))\n",
    "precipitation_satellite.set_index(precipitation_satellite['Date'],inplace=True)\n",
    "precipitation_satellite = precipitation_satellite.drop('Date',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_satellite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1f5926",
   "metadata": {},
   "source": [
    "Calcular la precipitación anual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf220da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_annual = precipitation_satellite.resample('Y',label='right',closed='right').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181311c8",
   "metadata": {},
   "source": [
    "Graficar precipitación promedio anual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "# Assuming dataset is a pandas DataFrame with labeled columns\n",
    "data_annual.plot(kind='bar', ax=ax)\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Precipitation_satellite (mm)')\n",
    "# Adjusting the position of the legend\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd41dc08",
   "metadata": {},
   "source": [
    "Calcular precipitación anual promedio de todos los pixeles de la cuenca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_annual_average =  data_annual.mean(axis=1)\n",
    "data_annual_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268a4c9d",
   "metadata": {},
   "source": [
    "Graficar la precipitación promedio (todos los pixeles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77108f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "# Assuming dataset is a pandas DataFrame with labeled columns\n",
    "data_annual_average.plot(kind='bar', ax=ax)\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Precipitation_satellite (mm)')\n",
    "# Adjusting the position of the legend\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5566822",
   "metadata": {},
   "source": [
    "Calcular la precipitación anual promedio en la cuenca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158532d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_annual_average.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a04b0b3",
   "metadata": {},
   "source": [
    "Calcular la precipitación mensual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdcc548",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_monthly = precipitation_satellite.resample('M',label='right',closed='right').sum() \n",
    "data_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc05667b",
   "metadata": {},
   "source": [
    "Calcular precipitación promedio mensual de todos los pixeles de la cuenca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599bc0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_monthly_mean_pixels =  data_monthly.mean(axis=1)\n",
    "data_monthly_mean_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc48a367",
   "metadata": {},
   "source": [
    "Graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59682b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(40,5))\n",
    "# Assuming dataset is a pandas DataFrame with labeled columns\n",
    "data_monthly_mean_pixels.plot(kind='bar', ax=ax)\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Precipitation_satellite (mm)')\n",
    "# Adjusting the position of the legend\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4698599c",
   "metadata": {},
   "source": [
    "Calcular precipitación promedio mensual (promedio de todos los pixeles de la cuenca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe79312",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_monthly_mean= data_monthly_mean_pixels.groupby(data_monthly_mean_pixels.index.month).mean()\n",
    "data_monthly_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edc31a",
   "metadata": {},
   "source": [
    "Graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71489e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "# Assuming dataset is a pandas DataFrame with labeled columns\n",
    "data_monthly_mean.plot(kind='bar', ax=ax)\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Precipitation_satellite (mm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663db72f",
   "metadata": {},
   "source": [
    "### Importar precipitación in-situ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74626f",
   "metadata": {},
   "source": [
    "Disponemos de tres pluviómetros instalados dentro de la cuenca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358feba1",
   "metadata": {},
   "source": [
    "#### Para el pluviómetro 1\n",
    "\n",
    "\n",
    "Importar y preprocesar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed797176",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_pcp_1 = folder+'Pluviómetro_1/'\n",
    "df_pcp_1= pd.read_table(folder_pcp_1+'Pluviómetro_1.csv', sep=',')\n",
    "df_pcp_1.rename(columns={'Texas_tip_corrected_mm':'Pluviómetro_1'},inplace=True)\n",
    "df_pcp_1.columns\n",
    "df_pcp_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af0132",
   "metadata": {},
   "source": [
    "Operaciones para ordenar la información en un dataframe manejable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5cf6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pcp_1.rename(columns={'Date_yy/mm/dd_hh:mm:ss':'Date'},inplace=True)\n",
    "df_pcp_1['Date'] = df_pcp_1.Date.apply(lambda x: pd.to_datetime(x,dayfirst=True))\n",
    "df_pcp_1.set_index(df_pcp_1['Date'],inplace=True)\n",
    "df_pcp_1 = df_pcp_1.drop('Date',1)\n",
    "df_pcp_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c639a",
   "metadata": {},
   "source": [
    "Graficar el año 2020 de la serie de precipitación importada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b21deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "# Assuming dataset is a pandas DataFrame with labeled columns\n",
    "df_pcp_1['2020'].plot(ax=ax)\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Precipitation_in situ (mm)')\n",
    "# Adjusting the position of the legend\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9ff66",
   "metadata": {},
   "source": [
    "Graficar la precipitación acumulada del 2020 de la serie temporal importada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "# Assuming dataset is a pandas DataFrame with labeled columns\n",
    "df_pcp_1['2020'].cumsum().plot(ax=ax)\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Precipitation_satellite (mm)')\n",
    "# Adjusting the position of the legend\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df75cf",
   "metadata": {},
   "source": [
    "#### Para el pluviómetro 2\n",
    "\n",
    "\n",
    "Importar y preprocesar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a4b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_pcp_2 = folder+'Pluviómetro_2/'\n",
    "df_pcp_2= pd.read_table(folder_pcp_2+'Pluviómetro_2.csv', sep=',')\n",
    "df_pcp_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f70661",
   "metadata": {},
   "source": [
    "Operaciones para crear un dataframe manejable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pcp_2['Date'] = df_pcp_2.Date.apply(lambda x: pd.to_datetime(x,dayfirst=True))\n",
    "df_pcp_2.set_index(df_pcp_2['Date'],inplace=True)\n",
    "df_pcp_2 = df_pcp_2.drop('Date',1)\n",
    "df_pcp_2.rename(columns={'Precipitation':'Pluviómetro_2'},inplace=True)\n",
    "df_pcp_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2dd1e4",
   "metadata": {},
   "source": [
    "Graficar el año 2020 de la serie importada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c1ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "# Assuming dataset is a pandas DataFrame with labeled columns\n",
    "df_pcp_2['2020'].plot(ax=ax)\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Precipitation_in situ (mm)')\n",
    "# Adjusting the position of the legend\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d543a42",
   "metadata": {},
   "source": [
    "Graficar la precipitacióm acumulada del año 2020 de la serie importada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed87ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "# Assuming dataset is a pandas DataFrame with labeled columns\n",
    "df_pcp_2['2020'].cumsum().plot(ax=ax)\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Precipitation_satellite (mm)')\n",
    "# Adjusting the position of the legend\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5b01be",
   "metadata": {},
   "source": [
    "#### Para el pluviómetro 3\n",
    "\n",
    "\n",
    "Importar y preprocesar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_pcp_3 = folder+'Pluviómetro_3/'\n",
    "df_pcp_3= pd.read_table(folder_pcp_3+'Pluviómetro_3.csv', sep=',')\n",
    "df_pcp_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4364bec1",
   "metadata": {},
   "source": [
    "Operaciones para crear un dataframe manejable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc48890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pcp_3['Fecha'] = df_pcp_3.Fecha.apply(lambda x: pd.to_datetime(x,dayfirst=True))\n",
    "df_pcp_3.set_index(df_pcp_3['Fecha'],inplace=True)\n",
    "df_pcp_3 = df_pcp_3.drop('Fecha',1)\n",
    "df_pcp_3.rename(columns={'Precipitation':'Pluviómetro_3'},inplace=True)\n",
    "df_pcp_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d012d8",
   "metadata": {},
   "source": [
    "Graficar la precipitación del año 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df650fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "# Assuming dataset is a pandas DataFrame with labeled columns\n",
    "df_pcp_3['2020'].plot(ax=ax)\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Precipitation_in situ (mm)')\n",
    "# Adjusting the position of the legend\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342ef0a7",
   "metadata": {},
   "source": [
    "Graficar la precipitación acumulada del año 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a757f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "# Assuming dataset is a pandas DataFrame with labeled columns\n",
    "df_pcp_3['2020'].cumsum().plot(ax=ax)\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Precipitation_satellite (mm)')\n",
    "# Adjusting the position of the legend\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab62747",
   "metadata": {},
   "source": [
    "#### Comparar la precipitación in-situ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d1637",
   "metadata": {},
   "source": [
    "Remuestrear la información de los 3 pluviómetros a escalas mensuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pcp_1_monthly = df_pcp_1.resample('M',label='right',closed='right').sum() \n",
    "df_pcp_1_monthly= df_pcp_1_monthly.groupby(df_pcp_1_monthly.index.month).mean()\n",
    "df_pcp_2_monthly = df_pcp_2.resample('M',label='right',closed='right').sum() \n",
    "df_pcp_2_monthly= df_pcp_2_monthly.groupby(df_pcp_2_monthly.index.month).mean()\n",
    "df_pcp_3_monthly = df_pcp_3.resample('M',label='right',closed='right').sum() \n",
    "df_pcp_3_monthly= df_pcp_3_monthly.groupby(df_pcp_3_monthly.index.month).mean()\n",
    "all_pcp_monthly = pd.concat([df_pcp_1_monthly, df_pcp_2_monthly, df_pcp_3_monthly], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9225f235",
   "metadata": {},
   "source": [
    "Graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "# Assuming dataset is a pandas DataFrame with labeled columns\n",
    "all_pcp_monthly.plot(kind='bar',ax=ax)\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Precipitation_in situ (mm)')\n",
    "# Adjusting the position of the legend\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a67fb1e",
   "metadata": {},
   "source": [
    "## Importar datos de caudal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59bddd9",
   "metadata": {},
   "source": [
    "Importar y organizar los datos caudal en un dataframe manejable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edac2779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_caudal = folder+'Caudal_Tomebamba/'\n",
    "df_caudal =  pd.read_excel(folder_caudal+'Tomebamba.xlsx')\n",
    "df_caudal['Fecha'] = df_caudal.Fecha.apply(lambda x: pd.to_datetime(x,dayfirst=True))\n",
    "df_caudal.set_index(df_caudal['Fecha'],inplace=True)\n",
    "df_caudal = df_caudal.drop('Fecha',1)\n",
    "df_caudal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ca367",
   "metadata": {},
   "source": [
    "Graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "# Assuming dataset is a pandas DataFrame with labeled columns\n",
    "df_caudal.plot(ax=ax)\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Caudal ($m^3/s$)')\n",
    "# Adjusting the position of the legend\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ada5a4f",
   "metadata": {},
   "source": [
    "## Unir los datos de precipitación (pluviómetros+satelitales) y caudal de la cuenca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37efa7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pcp_1_daily = df_pcp_1.resample('D',label='right',closed='right').sum() \n",
    "df_pcp_2_daily = df_pcp_2.resample('D',label='right',closed='right').sum() \n",
    "df_pcp_3_daily = df_pcp_3.resample('D',label='right',closed='right').sum() \n",
    "df_caudal_daily = df_caudal.resample('D',label='right',closed='right').mean() \n",
    "all_data_daily = pd.concat([df_pcp_1_daily, df_pcp_2_daily, df_pcp_3_daily, precipitation_satellite, df_caudal_daily], axis=1)\n",
    "all_data_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b3e6a2",
   "metadata": {},
   "source": [
    "### Determinar periodos con datos concurrentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2dd767",
   "metadata": {},
   "outputs": [],
   "source": [
    "concurrent_periods = all_data_daily.dropna().index\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Loop through columns\n",
    "for i, col in enumerate(all_data_daily.columns):\n",
    "    # Get a boolean mask where data is not NaN for the current column\n",
    "    mask = ~all_data_daily[col].isna()\n",
    "    \n",
    "    # Get the indices of True values in the mask\n",
    "    indices = np.where(mask)[0]\n",
    "    \n",
    "    # Plot horizontal lines for continuity\n",
    "    ax.hlines(i, indices[0], indices[-1], colors='0.1', linewidth=5, label=col)\n",
    "\n",
    "# Set y-ticks and labels\n",
    "ax.set_yticks(range(len(all_data_daily.columns)))\n",
    "ax.set_yticklabels(all_data_daily.columns)\n",
    "\n",
    "# Set x-axis label\n",
    "ax.set_xlabel('Date')\n",
    "\n",
    "# Set the x-axis ticks to show years\n",
    "years = pd.to_datetime(all_data_daily.index).year\n",
    "unique_years = np.unique(years)\n",
    "ax.set_xticks(np.arange(len(all_data_daily.index), step=365))\n",
    "ax.set_xticklabels(unique_years,rotation=45)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=11)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21eafa",
   "metadata": {},
   "source": [
    "## Dividir datos en periodos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_daily = all_data_daily[~(all_data_daily.isna().any(axis=1) | (all_data_daily.lt(0).any(axis=1)))]\n",
    "input_data_train = np.array(all_data_daily['2013':'2019'].iloc[:,:-1])\n",
    "input_data_test = np.array(all_data_daily['2020':'2021-06'].iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423cd98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_train = np.reshape(np.array(all_data_daily['2013':'2019'].iloc[:,-1]),(all_data_daily['2013':'2019'].shape[0],1))\n",
    "output_data_test = np.reshape(np.array(all_data_daily['2020':'2021-06'].iloc[:,-1]),(all_data_daily['2020':'2021-06'].shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5501952",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_train_lags, output_data_train_lags= lagged_dataset(input_data_train, 3, output_data_train,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c5bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_train_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec645947",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_train_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a37b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_test_lags, output_data_test_lags= lagged_dataset(input_data_test, 3, output_data_test,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e74788",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_test_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42cf385",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_test_lags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae96a3d",
   "metadata": {},
   "source": [
    "## Creación y entrenamiento de un modelo de Random Forest (no pronóstico)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b78f49",
   "metadata": {},
   "source": [
    "### Definir hiperparámetros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad963f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_splt=10\n",
    "min_samples_lf=4\n",
    "max_dpth=350\n",
    "n_trees=600\n",
    "max_ft='sqrt'                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc8e865",
   "metadata": {},
   "source": [
    "### Definir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23362103",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr=RandomForestRegressor(bootstrap=True,min_samples_split=min_samples_splt,\n",
    "                               max_depth=max_dpth,max_features=max_ft,\n",
    "                               min_samples_leaf=min_samples_lf,\n",
    "                               n_estimators=n_trees,oob_score=True,n_jobs=-1,\n",
    "                               warm_start=True,random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea50d345",
   "metadata": {},
   "source": [
    "### Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr=regr.fit(input_data_train_lags, output_data_train_lags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6bd88b",
   "metadata": {},
   "source": [
    "### Generar simulaciones para el periodo de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403bbb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations_data_train= regr.predict(input_data_train_lags)\n",
    "simulations_data_train= np.reshape(simulations_data_train, (-1, 1))\n",
    "simulations_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac04b9",
   "metadata": {},
   "source": [
    "### Generar simulaciones para el periodo de prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcaf0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on unseen data\n",
    "simulations_data_test= regr.predict(input_data_test_lags)\n",
    "simulations_data_test= np.reshape(simulations_data_test, (-1, 1))\n",
    "simulations_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf59b53",
   "metadata": {},
   "source": [
    "### Evaluación del modelo\n",
    "\n",
    "\n",
    "Calcular los coeficientes de correlación de los periodos de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
    "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
    "print(r2_train,r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bbbcc7",
   "metadata": {},
   "source": [
    "## Creación y entrenamiento de un modelo de Random Forest (pronóstico)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e2609b",
   "metadata": {},
   "source": [
    "### Caso de pronóstico de 1 día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventana_pronostico = 1\n",
    "input_data_train_lags, output_data_train_lags= lagged_dataset_pron(input_data_train, 7, output_data_train,15, lead_time=ventana_pronostico)\n",
    "input_data_test_lags, output_data_test_lags= lagged_dataset_pron(input_data_test, 7, output_data_test,15, lead_time=ventana_pronostico)\n",
    "min_samples_splt=10\n",
    "min_samples_lf=4\n",
    "max_dpth=350\n",
    "n_trees=600\n",
    "max_ft='sqrt'                                             \n",
    "regr=RandomForestRegressor(bootstrap=True,min_samples_split=min_samples_splt,\n",
    "                               max_depth=max_dpth,max_features=max_ft,\n",
    "                               min_samples_leaf=min_samples_lf,\n",
    "                               n_estimators=n_trees,oob_score=True,n_jobs=-1,\n",
    "                               warm_start=True,random_state=42)\n",
    "regr=regr.fit(input_data_train_lags, output_data_train_lags)\n",
    "#Prediction on training data\n",
    "simulations_data_train= regr.predict(input_data_train_lags)\n",
    "simulations_data_train= np.reshape(simulations_data_train, (-1, 1))\n",
    "#Prediction on unseen data\n",
    "simulations_data_test= regr.predict(input_data_test_lags)\n",
    "simulations_data_test= np.reshape(simulations_data_test, (-1, 1))\n",
    "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
    "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
    "print(r2_train,r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4faead0",
   "metadata": {},
   "source": [
    "Los pronósticos en el periodo de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f3d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262ad4b",
   "metadata": {},
   "source": [
    "### Evaluación usando una combinación de métricas de eficiencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9997523",
   "metadata": {},
   "outputs": [],
   "source": [
    "kge, rmse, pbias , r2 = calculate_hydro_metrics(simulations_data_test, output_data_test_lags)\n",
    "print(f\"RMSE: {rmse[0]:.4f}\")\n",
    "print(f\"PBias: {pbias[0]:.4f}\")\n",
    "print(f\"KGE: {kge[0]:.4f}\")\n",
    "print(f\"R2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdf224",
   "metadata": {},
   "source": [
    "### Evaluación a través de inspección visual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd0d7d",
   "metadata": {},
   "source": [
    "Pronósticos de caudal 1 día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations_data_test = pd.DataFrame(simulations_data_test, columns=['Pronósticos'], index=all_data_daily['2019':'2021-06'].index[-len(simulations_data_test):])\n",
    "simulations_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a564c026",
   "metadata": {},
   "source": [
    "Y las observaciones de caudal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72705ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_data_test = pd.DataFrame(output_data_test_lags, columns=['Observaciones'], index=all_data_daily['2019':'2021-06'].index[-len(output_data_test_lags):])\n",
    "observations_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d72102a",
   "metadata": {},
   "source": [
    "Juntar pronósticos y observaciones en un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period = pd.concat([simulations_data_test, observations_data_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd4499",
   "metadata": {},
   "source": [
    "Graficar (comparar) pronósticos y observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Assuming testing_period is a pandas DataFrame with labeled columns\n",
    "testing_period['Pronósticos'].plot(color='red', marker='o', linestyle='', markersize=2)\n",
    "testing_period['Observaciones'].plot( color='black', linestyle='-')\n",
    "# Adding labels for the legend\n",
    "plt.legend(title='Legend Title')\n",
    "\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Caudal ($m^3/s$)')\n",
    "\n",
    "# Adjusting the position of the legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9500b",
   "metadata": {},
   "source": [
    "Gráfico de dispersión entre pronósticos y observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592c0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming testing_period is a pandas DataFrame with labeled columns\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# Scatter plot for Observaciones\n",
    "x = testing_period['Observaciones']\n",
    "y = testing_period['Pronósticos']\n",
    "sns.scatterplot(x=x, y=y, color='red', marker='o', s=30, label='Observaciones vs Pronósticos', ax=ax)\n",
    "# KDE plot for density\n",
    "# Assuming x and y are your data arrays\n",
    "# Concatenate x and y into a single array\n",
    "data = np.vstack((x, y)).T\n",
    "sns.kdeplot(x=x,y=y,cmap='magma', ax=ax, fill=False, thresh=0, levels=13, legend=False)\n",
    "# Add a bisector line (y = x)\n",
    "min_val = min(x.min(), y.min())\n",
    "max_val = max(x.max(), y.max())\n",
    "ax.plot([min_val, max_val], [min_val, max_val], color='blue', linestyle='--', label='Bisector Line')\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "# Adding a label to the y-axis\n",
    "ax.set_ylabel('Caudal ($m^3/s$)')\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c527a2",
   "metadata": {},
   "source": [
    "## Incluir datos ENSO\n",
    "\n",
    "\n",
    "https://psl.noaa.gov/gcos_wgsp/Timeseries/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ed620",
   "metadata": {},
   "source": [
    "Importar datos de El Niño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f2665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to \n",
    "folder_nino12 = folder+'ENSO/nino12.long.anom.data.xlsx'\n",
    "folder_nino3 = folder+'ENSO/nino3.long.anom.data.xlsx'\n",
    "folder_nino34 = folder+'ENSO/nino34.long.anom.data.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7adbb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tabula to extract tables\n",
    "nino12 =  pd.read_excel(folder_nino12)\n",
    "nino3 =  pd.read_excel(folder_nino3)\n",
    "nino34 =  pd.read_excel(folder_nino34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bef597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame to convert it to long format\n",
    "nino12_long = nino12.melt(id_vars=['Year'], var_name='Month', value_name='Data')\n",
    "# Replace '-99.99' values with NaN\n",
    "nino12_long['Data'] = nino12_long['Data'].replace(-99.99, np.nan)\n",
    "# Convert 'Year' and 'Month' to datetime format\n",
    "nino12_long['Date'] = pd.to_datetime(nino12_long['Year'].astype(str) + '-' + nino12_long['Month'], format='%Y-%B')\n",
    "# Set 'Date' as the index\n",
    "nino12_time_series = nino12_long.set_index('Date')[['Data']]\n",
    "# Display the resulting DataFrame\n",
    "nino12_time_series\n",
    "\n",
    "# Melt the DataFrame to convert it to long format\n",
    "nino3_long = nino3.melt(id_vars=['Year'], var_name='Month', value_name='Data')\n",
    "# Replace '-99.99' values with NaN\n",
    "nino3_long['Data'] = nino3_long['Data'].replace(-99.99, np.nan)\n",
    "# Convert 'Year' and 'Month' to datetime format\n",
    "nino3_long['Date'] = pd.to_datetime(nino3_long['Year'].astype(str) + '-' + nino3_long['Month'], format='%Y-%B')\n",
    "# Set 'Date' as the index\n",
    "nino3_time_series = nino3_long.set_index('Date')[['Data']]\n",
    "# Display the resulting DataFrame\n",
    "nino3_time_series\n",
    "\n",
    "# Melt the DataFrame to convert it to long format\n",
    "nino34_long = nino34.melt(id_vars=['Year'], var_name='Month', value_name='Data')\n",
    "# Replace '-99.99' values with NaN\n",
    "nino34_long['Data'] = nino34_long['Data'].replace(-99.99, np.nan)\n",
    "# Convert 'Year' and 'Month' to datetime format\n",
    "nino34_long['Date'] = pd.to_datetime(nino34_long['Year'].astype(str) + '-' + nino34_long['Month'], format='%Y-%B')\n",
    "# Set 'Date' as the index\n",
    "nino34_time_series = nino34_long.set_index('Date')[['Data']]\n",
    "# Display the resulting DataFrame\n",
    "nino34_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7c59e",
   "metadata": {},
   "source": [
    "Pasar de datos mensuales a diarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "nino12_df = nino12_time_series.resample('D').ffill()\n",
    "nino3_df = nino3_time_series.resample('D').ffill()\n",
    "nino34_df = nino34_time_series.resample('D').ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1aff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSO_daily = pd.concat([nino12_df,nino3_df,nino34_df], axis=1)\n",
    "ENSO_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286f86f",
   "metadata": {},
   "source": [
    "Juntar toda la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_daily_ENSO = pd.concat([all_data_daily, ENSO_daily], axis=1)\n",
    "all_data_daily_ENSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93021149",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_daily_ENSO['2013']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89c56f8",
   "metadata": {},
   "source": [
    "Definir periodos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fbce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_daily_ENSO = all_data_daily_ENSO[~(all_data_daily_ENSO.isna().any(axis=1))]\n",
    "all_data_daily_ENSO.shape\n",
    "inputs = all_data_daily_ENSO.drop(all_data_daily_ENSO.columns[-4], axis=1)\n",
    "input_data_train = np.array(inputs['2013':'2019'].iloc[:,:-1])\n",
    "input_data_test = np.array(inputs['2020':'2021-06'].iloc[:,:-1])\n",
    "output_data_train = np.reshape(np.array(all_data_daily_ENSO['2013':'2019'].iloc[:,-4]),(all_data_daily_ENSO['2013':'2019'].shape[0],1))\n",
    "output_data_test = np.reshape(np.array(all_data_daily_ENSO['2020':'2021-06'].iloc[:,-4]),(all_data_daily_ENSO['2020':'2021-06'].shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ea0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16484369",
   "metadata": {},
   "source": [
    "Desarrollo de modelos de pronóstico a 1 día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventana_pronostico = 1\n",
    "input_data_train_lags, output_data_train_lags= lagged_dataset_pron(input_data_train, 3, output_data_train,15, lead_time=ventana_pronostico)\n",
    "input_data_test_lags, output_data_test_lags= lagged_dataset_pron(input_data_test, 3, output_data_test,15, lead_time=ventana_pronostico)\n",
    "min_samples_splt=10\n",
    "min_samples_lf=4\n",
    "max_dpth=350\n",
    "n_trees=600\n",
    "max_ft='sqrt'                                             \n",
    "regr=RandomForestRegressor(bootstrap=True,min_samples_split=min_samples_splt,\n",
    "                               max_depth=max_dpth,max_features=max_ft,\n",
    "                               min_samples_leaf=min_samples_lf,\n",
    "                               n_estimators=n_trees,oob_score=True,n_jobs=-1,\n",
    "                               warm_start=True,random_state=22)\n",
    "regr=regr.fit(input_data_train_lags, output_data_train_lags)\n",
    "#Prediction on training data\n",
    "simulations_data_train_ENSO= regr.predict(input_data_train_lags)\n",
    "simulations_data_train_ENSO= np.reshape(simulations_data_train_ENSO, (-1, 1))\n",
    "#Prediction on unseen data\n",
    "simulations_data_test_ENSO= regr.predict(input_data_test_lags)\n",
    "simulations_data_test_ENSO= np.reshape(simulations_data_test_ENSO, (-1, 1))\n",
    "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
    "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
    "print(r2_train,r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7c6b18",
   "metadata": {},
   "source": [
    "### Evaluación con métricas de eficiencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aec896",
   "metadata": {},
   "outputs": [],
   "source": [
    "kge, rmse, pbias , r2 = calculate_hydro_metrics(simulations_data_test_ENSO, output_data_test_lags)\n",
    "print(f\"RMSE: {rmse[0]:.4f}\")\n",
    "print(f\"PBias: {pbias[0]:.4f}\")\n",
    "print(f\"KGE: {kge[0]:.4f}\")\n",
    "print(f\"R2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5719eb6",
   "metadata": {},
   "source": [
    "### Inspección visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations_data_test_ENSO = pd.DataFrame(simulations_data_test, columns=['Pronósticos'], index=all_data_daily['2019':'2021-06'].index[-len(simulations_data_test):])\n",
    "observations_data_test_ENSO = pd.DataFrame(output_data_test_lags, columns=['Observaciones'], index=all_data_daily['2019':'2021-06'].index[-len(output_data_test_lags):])\n",
    "testing_period_ENSO = pd.concat([simulations_data_test_ENSO, observations_data_test_ENSO], axis=1)\n",
    "fig, ax= plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Assuming testing_period is a pandas DataFrame with labeled columns\n",
    "testing_period_ENSO['Pronósticos'].plot(color='red', marker='o', linestyle='', markersize=2)\n",
    "testing_period_ENSO['Observaciones'].plot( color='black', linestyle='-')\n",
    "\n",
    "# Adding labels for the legend\n",
    "plt.legend(title='Legend Title')\n",
    "\n",
    "# Adding a label to the y-axis\n",
    "plt.ylabel('Caudal ($m^3/s$)')\n",
    "\n",
    "# Adjusting the position of the legend\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming testing_period is a pandas DataFrame with labeled columns\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Scatter plot for Observaciones\n",
    "x = testing_period_ENSO['Observaciones']\n",
    "y = testing_period_ENSO['Pronósticos']\n",
    "sns.scatterplot(x=x, y=y, color='red', marker='o', s=30, label='Observaciones vs Pronósticos', ax=ax)\n",
    "\n",
    "# KDE plot for density\n",
    "\n",
    "\n",
    "data = np.vstack((x, y)).T\n",
    "\n",
    "sns.kdeplot(x=x, y=y, cmap='magma', ax=ax, fill=False, thresh=0, levels=13, legend=False)\n",
    "\n",
    "# Add a bisector line (y = x)\n",
    "min_val = min(x.min(), y.min())\n",
    "max_val = max(x.max(), y.max())\n",
    "ax.plot([min_val, max_val], [min_val, max_val], color='blue', linestyle='--', label='Bisector Line')\n",
    "\n",
    "# Adding labels for the legend\n",
    "ax.legend(title='Legend Title')\n",
    "\n",
    "# Adding a label to the y-axis\n",
    "ax.set_ylabel('Caudal ($m^3/s$)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252fee0b",
   "metadata": {},
   "source": [
    "## Hiperparametrización del modelo de pronóstico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ad488",
   "metadata": {},
   "source": [
    "Definir dominio de búsqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44fb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'min_samples_split': [ 10, 20],\n",
    "    'min_samples_leaf': [2, 10],\n",
    "    'max_depth': [100, 300],\n",
    "    'n_estimators': [300, 500],\n",
    "    'max_features': ['sqrt','log2']\n",
    "}\n",
    "\n",
    "# Calculate the total number of combinations\n",
    "total_combinations = len(list(itertools.product(*param_grid.values())))\n",
    "\n",
    "total_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6b2a3",
   "metadata": {},
   "source": [
    "Búsqueda de mejor combinación de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a17f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(oob_score=True, n_jobs=-1, warm_start=True),\n",
    "                           param_grid=param_grid, cv=3, n_jobs=-1, scoring='r2')\n",
    "\n",
    "# Fit the GridSearchCV to your data\n",
    "grid_search.fit(input_data_train_lags, output_data_train_lags)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c23de2f",
   "metadata": {},
   "source": [
    "Una hiperparametrización más rigurosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dceff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'min_samples_split': [5, 10, 20],\n",
    "    'min_samples_leaf': [2, 4, 8],\n",
    "    'max_depth': [100, 200, 350],\n",
    "    'n_estimators': [200, 300, 400, 500, 600],\n",
    "    'max_features': ['auto', 'sqrt','log2']\n",
    "}\n",
    "# Calculate the total number of combinations\n",
    "total_combinations = len(list(itertools.product(*param_grid.values())))\n",
    "\n",
    "total_combinations\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(oob_score=True, n_jobs=-1, warm_start=True),\n",
    "                           param_grid=param_grid, cv=3, n_jobs=-1, scoring='r2')\n",
    "\n",
    "# Fit the GridSearchCV to your data\n",
    "grid_search.fit(input_data_train_lags, output_data_train_lags)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af12c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model\n",
    "simulations_data_train_ENSO= best_model.predict(input_data_train_lags)\n",
    "simulations_data_train_ENSO= np.reshape(simulations_data_train_ENSO, (-1, 1))\n",
    "#Prediction on unseen data\n",
    "simulations_data_test_ENSO= best_model.predict(input_data_test_lags)\n",
    "simulations_data_test_ENSO= np.reshape(simulations_data_test_ENSO, (-1, 1))\n",
    "#Nash_Sutcliffe    \n",
    "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
    "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
    "print(r2_train,r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b85a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81fb23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventana_pronostico = 1\n",
    "input_data_train_lags, output_data_train_lags= lagged_dataset_pron(input_data_train, 3, output_data_train,15, lead_time=ventana_pronostico)\n",
    "input_data_test_lags, output_data_test_lags= lagged_dataset_pron(input_data_test, 3, output_data_test,15, lead_time=ventana_pronostico)\n",
    "min_samples_splt=10\n",
    "min_samples_lf=2\n",
    "max_dpth=300\n",
    "n_trees=300\n",
    "max_ft='sqrt'                                             \n",
    "regr=RandomForestRegressor(bootstrap=True,min_samples_split=min_samples_splt,\n",
    "                               max_depth=max_dpth,max_features=max_ft,\n",
    "                               min_samples_leaf=min_samples_lf,\n",
    "                               n_estimators=n_trees,oob_score=True,n_jobs=-1,\n",
    "                               warm_start=True,random_state=22)\n",
    "regr=regr.fit(input_data_train_lags, output_data_train_lags)\n",
    "#Prediction on training data\n",
    "simulations_data_train_ENSO= regr.predict(input_data_train_lags)\n",
    "simulations_data_train_ENSO= np.reshape(simulations_data_train_ENSO, (-1, 1))\n",
    "#Prediction on unseen data\n",
    "simulations_data_test_ENSO= regr.predict(input_data_test_lags)\n",
    "simulations_data_test_ENSO= np.reshape(simulations_data_test_ENSO, (-1, 1))\n",
    "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
    "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
    "print(r2_train,r2_test)\n",
    "kge, rmse, pbias , r2 = calculate_hydro_metrics(simulations_data_test_ENSO, output_data_test_lags)\n",
    "print(f\"RMSE: {rmse[0]:.4f}\")\n",
    "print(f\"PBias: {pbias[0]:.4f}\")\n",
    "print(f\"KGE: {kge[0]:.4f}\")\n",
    "print(f\"R2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a75af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72df12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ca521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c0f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44848e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
